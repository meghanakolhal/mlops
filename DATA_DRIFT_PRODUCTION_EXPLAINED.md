# Production Data Drift - Complete Explanation

## ğŸ¯ Your Questions Answered

### 1. "How does data drift work in production?"

**Simple Answer:**
- You keep **one reference dataset** (original training data)
- New production data arrives daily/weekly
- Compare new data **distribution** vs reference distribution
- If distributions differ significantly â†’ **DRIFT DETECTED!**

### 2. "Data will be added to one folder only, right?"

**Answer:** Yes! Recommended structure:

```
gs://ml-model-bucket-22/datasets/
â”œâ”€â”€ tickets.csv           # Reference data (baseline - never changes)
â”œâ”€â”€ new_tickets.csv       # New production data (updated daily/weekly)
â””â”€â”€ combined_tickets.csv # Reference + new (created during retraining)
```

**Why separate files?**
- `tickets.csv` = **Fixed reference** (always compare against this)
- `new_tickets.csv` = **Current new data** (changes over time)
- `combined_tickets.csv` = **For retraining** (reference + new combined)

### 3. "Will they maintain one data just to compare?"

**Answer:** Yes! Two approaches:

**Approach A: Fixed Reference** (Recommended âœ…)
- Keep `tickets.csv` as **permanent baseline**
- Always compare new data against this fixed reference
- Easy to track: "How much has data changed since original training?"

**Approach B: Rolling Reference**
- After retraining, update reference to latest combined data
- Compare new data against "last retrained" data
- More complex but adapts faster

**We're using Approach A** - fixed reference!

---

## ğŸ”„ Complete Production Workflow

### Step 1: Initial Setup
```
1. Upload reference data â†’ datasets/tickets.csv
2. Train model â†’ ticket_urgency_model/ticket_urgency_model.pkl
3. Deploy API â†’ API loads model
```

### Step 2: Daily Monitoring (Automated)
```
1. Monitoring DAG runs daily
2. Loads reference: datasets/tickets.csv
3. Loads new data: datasets/new_tickets.csv (if exists)
4. Compares distributions:
   - source (email/web/phone) distribution
   - customer_tier (Gold/Silver/Bronze) distribution
5. If difference > 10% â†’ DRIFT DETECTED!
6. Saves report to monitoring/report_*.json
```

### Step 3: When New Data Arrives
```
1. Collect new production tickets
2. Upload to GCS: datasets/new_tickets.csv
   (Can append or replace - your choice)
```

### Step 4: Retrain After Drift
```
1. Run combine_and_retrain.py:
   - Loads reference: datasets/tickets.csv
   - Loads new: datasets/new_tickets.csv
   - Combines them
   - Trains new model
   - Uploads to GCS (overwrites old model)
2. Model file updated â†’ timestamp changes
3. API detects change â†’ auto-reloads model âœ…
```

### Step 5: API Cache Management

**Problem:** API caches model in memory and `/tmp/model.pkl`

**Solution Implemented:**
- API checks model's **updated timestamp** in GCS
- If timestamp changed â†’ **automatically reloads**
- No manual cache clearing needed!

**Manual Option:**
- Call `/reload-model` endpoint to force reload

---

## ğŸ“Š Data Organization Strategy

### Recommended Structure:

```
gs://ml-model-bucket-22/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ tickets.csv              # Reference (baseline - fixed)
â”‚   â”œâ”€â”€ new_tickets.csv           # New production data (updated)
â”‚   â””â”€â”€ combined_tickets.csv      # Combined (for retraining)
â”œâ”€â”€ ticket_urgency_model/
â”‚   â””â”€â”€ ticket_urgency_model.pkl  # Current model (updated on retrain)
â””â”€â”€ monitoring/
    â””â”€â”€ report_*.json            # Daily monitoring reports
```

### Why This Structure?

1. **`tickets.csv`** (Reference):
   - Original training data
   - **Never changes** (or only when you explicitly update baseline)
   - Used for drift comparison

2. **`new_tickets.csv`** (New Data):
   - Current production tickets
   - Updated daily/weekly
   - Compared against reference

3. **`combined_tickets.csv`** (Combined):
   - Created during retraining
   - Reference + new data
   - Used for training new model

---

## ğŸ”§ API Cache Clearing - How It Works

### Before (Problem):
```
1. Model cached in memory: model = <loaded_model>
2. Model cached on disk: /tmp/model.pkl
3. New model uploaded to GCS
4. API still uses old cached model âŒ
```

### After (Solution):
```
1. API checks model version (updated timestamp) on each request
2. If GCS model updated â†’ timestamp changed
3. API detects change â†’ clears cache â†’ reloads model âœ…
4. New model automatically used!
```

### Code Logic:

```python
# In download_model_from_gcs():
# 1. Get model version from GCS (updated timestamp)
gcs_version = blob.updated.isoformat()

# 2. Compare with cached version
if cached_version != gcs_version:
    # Model changed! Reload
    model = None  # Clear memory
    os.remove(MODEL_CACHE_PATH)  # Clear disk cache
    download_from_gcs()  # Download new model
```

---

## ğŸš€ Complete Testing Workflow

### 1. Upload New Data
```bash
# Upload new tickets with different distribution
gsutil cp data/raw/new_tickets.csv gs://ml-model-bucket-22/datasets/new_tickets.csv
```

### 2. Run Monitoring
```
Airflow UI â†’ Trigger monitoring DAG
â†’ Should detect drift!
```

### 3. Retrain Model
```bash
# Option A: Via Airflow DAG
Airflow UI â†’ Trigger retrain_model DAG

# Option B: Manual script
python scripts/combine_and_retrain.py
```

### 4. Verify API Reloads
```bash
# Check health - should show new model_version
curl https://ticket-urgency-api-7j3n5753uq-el.a.run.app/health

# Or force reload
curl -X POST https://ticket-urgency-api-7j3n5753uq-el.a.run.app/reload-model
```

---

## âœ… Summary

1. âœ… **Reference data**: `datasets/tickets.csv` (fixed baseline)
2. âœ… **New data**: `datasets/new_tickets.csv` (updated regularly)
3. âœ… **Drift detection**: Compares reference vs new distributions
4. âœ… **Retraining**: Combines reference + new â†’ trains â†’ uploads model
5. âœ… **API cache**: Auto-reloads when model version changes
6. âœ… **Manual reload**: `/reload-model` endpoint available

**Everything is set up!** Ready to test the complete workflow! ğŸš€
